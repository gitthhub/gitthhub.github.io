---
layout:     post
title:      CNN Model - VGGNet
subtitle:   论文分析
date:       2019-03-26
author:     vhpg
header-img: img/placeholder_img.png
catalog: true
tags:
    - Deep Learning
    - CNN Model
---
> 本篇文章观点仅限于目前的理解，后续若有新的理解，还会继续更新。

#### 1. Introduce
  VGGNet是在2015年发表在ICLR上的一篇文章中提出的，网络深度提高到了16至19层，在ILSVRC-2014中，基于该网络的方案获得了Localisation任务的第一名和Classification任务的第二名(同年Classification任务第一名为Inception v1方案)。

  VGGNet出现前，网络最深也只在10层以内，此时的大多数工作是一方面是使用更小的卷积核和卷积步长，另一方面是使用更大的图像和多尺度对图像进行训练，本文中作者则从另一个角度研究CNN网络的特性--`Depth`。

  VGGNet的网络结构并没有太多可以分析的地方，作者设计网络的思路也很简单，全部使用`3*3`大小的卷积核，并在不同的网络结构中加入`1*1`的卷积核进行对比，剩下的工作就是不断增加网络深度，以分析不同深度对分类精度的影响，如下图所示，VGGNet最深的结构达到了19层，**VGG-19** 也是现在用的比较多的一个预训练模型，在当时算是比较深的网络，同时也得出结论:**较小的卷积核和较深的网络结构可以提高模型精度**。
  ![2019-03-26_102501](/assets/2019-03-26_102501.png)

  下图为VGG-16的空间直观图：
  ![Selection_001](/assets/Selection_001.png)

  下面主要分析一下论文中实验部分的内容。

#### 2. Training
  ##### 参数设置
  * batch size = 256
  * momentum = 0.9
  * L2正则化项
  * 前两层全连接层使用Dropout = 0.5
  * learning rate = 1e-2  验证集精度停止增加时，lr降低十倍

  ##### 模型初始化
  这里作者使用的策略是：首先训练较浅的网络，在训练较深的网络时，使用较浅网络的一部分权重去初始化较深的网络，其他权重使用满足高斯分布的随机值进行初始化，bias初始化为0。

  ##### 图像增强
  作者使用了随机翻转和随机像素值漂移等图像增强方法，这里主要介绍作者对图像尺度的处理方法。

  在训练时，所有的VGGNet结构都使用`224*224`大小的图像作为输入，该大小的图像并非直接从原图像裁剪得到，而是先将原图像放缩至尺度S(S>=224)，然后再在S中随机裁剪出`224*224`的图像作为网络输入。

  将图像放缩至S的方法与NI论文中的类似：首先将图像的较短边缩放至S，长边按比例缩放至相似长度。

  将图像放缩至S，在训练时有以下两种考虑方式：
  * **Single Scale**: 该种情况下，在整个网络训练过程中，S始终为固定值，论文中选用的为256或384；

  * **Multi Scale**: 该种情况下，网络在对每个batch的图像进行处理时，先从某一个范围内选出一个S，然后将图像缩放至该S尺度后再从中裁剪图像，论文中选用的范围为`[256 512]`。

#### 3. Testing
  ##### 测试前的处理
  在网络训练完成后，作者对网络进行了一些处理，以使网络可以处理任何大小的图像。
  ![Selection_002](/assets/Selection_002.png)

  ##### Single Scale Evaluation


  ##### Multi-crop Evaluation

  ##### ConvNet Fusion





#### Reference
[VGGNet](https://arxiv.org/pdf/1409.1556.pdf)
[图片参考](https://zhuanlan.zhihu.com/p/42233779)

---
layout:     post
title:      Deep Learning - Optimizers
subtitle:   深度学习基础
date:       2019-04-01
author:     vhpg
header-img: img/placeholder_img.png
catalog: true
tags:
    - Machine Learning
    - Deep Learning
    - Mathematics
---
> 本篇文章观点仅限于目前的理解，后续若有新的理解，还会继续更新。

> 跟据Keras中优化器的总类，对神经网络训练时常用的优化器进行总结，主要总结优化原理，使用场景，优缺点及在Keras中的参数配置。

#### 1. SGD



[Reference](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)

#### 2. RMSprop



[Reference](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)


#### 3. Adagrad


#### 4. Adadelta


#### 5. Adam


#### 6. Adamax


#### 7. Nadam


#### Reference
[Keras](https://keras.io/optimizers/)
[CS231n]()
